{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import random\n",
    "import os.path\n",
    "\n",
    "import torchvision\n",
    "import torch.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, src_path, trg_path, transform):\n",
    "        self.src_path = src_path\n",
    "        self.trg_path = trg_path\n",
    "\n",
    "        self.src_images = os.listdir(src_path)\n",
    "        self.trg_images = os.listdir(trg_path)\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        src_img = Image.open(os.path.join(self.src_path, self.src_images[index]))\n",
    "        src_img = src_img.convert('RGB')\n",
    "        trg_img = Image.open(os.path.join(self.trg_path, self.trg_images[index]))\n",
    "        trg_img = trg_img.convert('RGB')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            src_img = self.transform(src_img)\n",
    "            trg_img = self.transform(trg_img)\n",
    "\n",
    "        return src_img, trg_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(batch_size, src_path, trg_path, transform, shuffle=True):\n",
    "    dataset = Dataset(src_path, trg_path, transform)\n",
    "    dataloader = data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=1)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(idx, name, in_c, out_c, activation, kernel_size=3, stride=1, padding=1, transpose=False, bn=True, bias=True, drop=False):\n",
    "    block = nn.Sequential()\n",
    "\n",
    "    if not transpose:\n",
    "        block.add_module(name + ' Conv2d' + idx, nn.Conv2d(in_c, out_c, kernel_size, stride, padding, bias=bias))\n",
    "    else:\n",
    "        block.add_module(name + ' Conv2d_Transpose' + idx, nn.ConvTranspose2d(in_c, out_c, kernel_size, stride, padding, bias=bias))\n",
    "    if bn:\n",
    "        block.add_module(name + ' Batch_norm' + idx, nn.BatchNorm2d(out_c))\n",
    "    if activation == 'relu':\n",
    "        block.add_module(name + ' ReLU' + idx, nn.ELU(inplace=True))\n",
    "    elif activation == 'leaky_relu':\n",
    "        block.add_module(name + ' Leaky_ReLU' + idx, nn.LeakyReLU(0.2, inplace=True))\n",
    "    elif activation == 'sigmoid':\n",
    "        block.add_module(name + ' Sigmoid' + idx, nn.Sigmoid())\n",
    "    elif activation == 'tanh':\n",
    "        block.add_module(name + ' Tanh' + idx, nn.Tanh())\n",
    "    if drop:\n",
    "        block.add_module(name + \" Drop_out\" + idx, nn.Dropout())\n",
    "    \n",
    "    return block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G(nn.Module):\n",
    "    \"\"\"\n",
    "    input : ? x 128 x 128 x 3\n",
    "    layer0 : ? x 128 x 128 x 32\n",
    "    layer1 : ? x 64 x 64 x 64\n",
    "    layer2 : ? x 32 x 32 x 128\n",
    "    layer3 : ? x 16 x 16 x 256\n",
    "    layer4 : ? x 8 x 8 x 512\n",
    "    layer5 : ? x 4 x 4 x 1024\n",
    "    dlayer4 : ? x 8 x 8 x 512\n",
    "    dlayer3 : ? x 16 x 16 x 256\n",
    "    dlayer2 : ? x 32 x 32 x 128\n",
    "    dlayer1 : ? x 64 x 64 x 64\n",
    "    dlayer0 : ? x 128 x 128 x 33\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(G, self).__init__()\n",
    "        self.name = \"G\"\n",
    "\n",
    "        self.build()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n) ** 0.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def build(self):\n",
    "        activation = 'leaky_relu'\n",
    "        self.pooling = nn.Sequential(nn.AvgPool2d((2, 2), 2))\n",
    "\n",
    "        # down\n",
    "        self.layer0_0 = conv_block('0_0', self.name, 3, 32, activation, kernel_size=4, stride=2)\n",
    "        self.layer0_1 = conv_block('0_1', self.name, 32, 32, activation)\n",
    "\n",
    "        self.layer1_0 = conv_block('1_0', self.name, 32, 64, activation, kernel_size=4, stride=2)\n",
    "        self.layer1_1 = conv_block('1_1', self.name, 64, 64, activation)\n",
    "\n",
    "        self.layer2_0 = conv_block('2_0', self.name, 64, 128, activation, kernel_size=4, stride=2)\n",
    "        self.layer2_1 = conv_block('2_1', self.name, 128, 128, activation)\n",
    "\n",
    "        self.layer3_0 = conv_block('3_0', self.name, 128, 256, activation, kernel_size=4, stride=2) \n",
    "        self.layer3_2 = conv_block('3_2', self.name, 256, 256, activation, drop=True) \n",
    "        \n",
    "        self.layer4_0 = conv_block('4_0', self.name, 256, 512, activation, kernel_size=4, stride=2)\n",
    "        self.layer4_2 = conv_block('4_2', self.name, 512, 256, activation)\n",
    "\n",
    "        # up\n",
    "        self.dlayer4_0 = conv_block('up4_0', self.name, 512, 512, activation, transpose=True, kernel_size=4, stride=2)\n",
    "        self.dlayer4_2 = conv_block('up4_2', self.name, 512, 256, activation, drop=True)\n",
    "\n",
    "        self.dlayer3_0 = conv_block('up3_0', self.name, 512, 256, activation, transpose=True, kernel_size=4, stride=2)\n",
    "        self.dlayer3_2 = conv_block('up3_2', self.name, 256, 128, activation)\n",
    "\n",
    "        self.dlayer2_0 = conv_block('up2_0', self.name, 256, 128, activation, transpose=True, kernel_size=4, stride=2)\n",
    "        self.dlayer2_1 = conv_block('up2_1', self.name, 128, 64, activation)\n",
    "\n",
    "        self.dlayer1_0 = conv_block('up1_0', self.name, 128, 64, activation, transpose=True, kernel_size=4, stride=2)\n",
    "        self.dlayer1_1 = conv_block('up1_1', self.name, 64, 32, activation)\n",
    "\n",
    "        self.dlayer0_0 = conv_block('up0_0', self.name, 64, 32, activation, transpose=True, kernel_size=4, stride=2)\n",
    "        self.dlayer0_1 = conv_block('up0_1', self.name, 32, 3, 'tanh')\n",
    "\n",
    "    def forward(self, x):\n",
    "        out0_0 = self.layer0_0(x)\n",
    "        out0_1 = self.layer0_1(out0_0)\n",
    "        \n",
    "        out1_0 = self.layer1_0(out0_1)\n",
    "        out1_1 = self.layer1_1(out1_0)\n",
    "\n",
    "        out2_0 = self.layer2_0(out1_1)\n",
    "        out2_1 = self.layer2_1(out2_0)\n",
    "\n",
    "        out3_0 = self.layer3_0(out2_1)\n",
    "        out3_2 = self.layer3_2(out3_0)\n",
    "\n",
    "        out4_0 = self.layer4_0(out3_2)\n",
    "        out4_2 = self.layer4_2(out4_0)\n",
    "        \n",
    "        cat_out5_2 = torch.cat((out4_2, self.pooling(out3_2)), 1)\n",
    "        dout4_0 = self.dlayer4_0(cat_out5_2)\n",
    "        dout4_2 = self.dlayer4_2(dout4_0)\n",
    "\n",
    "        cat_out4_2 = torch.cat((dout4_2, out3_2), 1)\n",
    "        dout3_0 = self.dlayer3_0(cat_out4_2)\n",
    "        dout3_2 = self.dlayer3_2(dout3_0)\n",
    "\n",
    "        cat_out3_2 = torch.cat((dout3_2, out2_1), 1)\n",
    "        dout2_0 = self.dlayer2_0(cat_out3_2)\n",
    "        dout2_1 = self.dlayer2_1(dout2_0)\n",
    "\n",
    "        cat_out2_1 = torch.cat((dout2_1, out1_1), 1)\n",
    "        dout1_0 = self.dlayer1_0(cat_out2_1)\n",
    "        dout1_1 = self.dlayer1_1(dout1_0)\n",
    "\n",
    "        cat_out1_1 = torch.cat((dout1_1, out0_1), 1)\n",
    "        dout0_0 = self.dlayer0_0(cat_out1_1)\n",
    "        dout0_1 = self.dlayer0_1(dout0_0)\n",
    "\n",
    "        return dout0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class D(nn.Module):\n",
    "    \"\"\"\n",
    "    input : ? x 128 x 128 x 6(3 x 2)\n",
    "    layer0 : ? x 128 x 128 x 32 \n",
    "    layer1 : ? x 64 x 64 x 64 \n",
    "    layer2 : ? x 32 x 32 x 128 \n",
    "    layer3 : ? x 31 x 31 x 256 \n",
    "    output : ? x 30 x 30 x 1 \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(D, self).__init__()\n",
    "        self.name = \"D\"\n",
    "        \n",
    "        self.build()\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n) ** 0.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def build(self):\n",
    "        activation = 'leaky_relu'\n",
    "\n",
    "        self.layer0 = conv_block('0', self.name, 6, 32, activation, bn=False, kernel_size=4, stride=2)\n",
    "\n",
    "        self.layer1_0 = conv_block('1_0', self.name, 32, 64, activation, kernel_size=4, stride=2)\n",
    "        self.layer1_1 = conv_block('1_1', self.name, 64, 64, activation)\n",
    "\n",
    "        self.layer2_0 = conv_block('2_0', self.name, 64, 128, activation)\n",
    "        self.layer2_1 = conv_block('2_1', self.name, 128, 128, activation)\n",
    "\n",
    "        self.layer3_0 = conv_block('3_0', self.name, 128, 256, activation, kernel_size=2, stride=1, padding=0) \n",
    "        self.layer3_1 = conv_block('3_1', self.name, 256, 256, activation) \n",
    "        self.layer3_2 = conv_block('3_2', self.name, 256, 256, activation) \n",
    "        \n",
    "        self.layer4_0 = conv_block('4_0', self.name, 256, 512, activation)\n",
    "        self.layer4_1 = conv_block('4_1', self.name, 512, 512, activation)\n",
    "        self.layer4_2 = conv_block('4_2', self.name, 512, 1, 'sigmoid', kernel_size=2, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, src_input, trg_input):\n",
    "        x = torch.cat((src_input, trg_input), 1)\n",
    "        out0 = self.layer0(x)\n",
    "\n",
    "        out1_0 = self.layer1_0(out0)\n",
    "        out1_1 = self.layer1_1(out1_0)\n",
    "\n",
    "        out2_0 = self.layer2_0(out1_1)\n",
    "        out2_1 = self.layer2_1(out2_0)\n",
    "\n",
    "        out3_0 = self.layer3_0(out2_1)\n",
    "        out3_1 = self.layer3_1(out3_0)\n",
    "        out3_2 = self.layer3_2(out3_1)\n",
    "\n",
    "        out4_0 = self.layer4_0(out3_2)\n",
    "        out4_1 = self.layer4_1(out4_0)\n",
    "        out4_2 = self.layer4_2(out4_1)\n",
    "\n",
    "        return out4_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2Pix:\n",
    "    def __init__(self, batch_size, epoch_iter, lr, src_path, trg_path, sample_img_path, save_model_path, restore_D_model_path, restore_G_model_path, gpu):\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch_iter = epoch_iter\n",
    "        self.lr = lr\n",
    "\n",
    "        self.src_path = src_path\n",
    "        self.trg_path = trg_path\n",
    "        self.sample_img_path = sample_img_path\n",
    "        self.save_model_path = save_model_path\n",
    "        self.restore_D_model_path = restore_D_model_path\n",
    "        self.restore_G_model_path = restore_G_model_path\n",
    "\n",
    "        self.D = D()\n",
    "        self.G = G()\n",
    "        self.d_step = 1\n",
    "        self.g_step = 1\n",
    "\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "                                            #  transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                                            #                       (0.229, 0.224, 0.225))])\n",
    "\n",
    "    def load_dataset(self):\n",
    "        src_data = dset.ImageFolder(self.src_path, self.transformations)\n",
    "        self.src_loader = DataLoader(src_data, batch_size=self.batch_size)\n",
    "        trg_data = dset.ImageFolder(self.trg_path, self.transformations)\n",
    "        self.trg_loader = DataLoader(trg_data, batch_size=self.batch_size)\n",
    "\n",
    "    def train(self):\n",
    "        data_loader = get_loader(self.batch_size, self.src_path, self.trg_path, self.transform)\n",
    "        print('Dataset Load Success!')\n",
    "\n",
    "        if len(self.restore_G_model_path):\n",
    "            self.D.load_state_dict(torch.load(self.restore_D_model_path))\n",
    "            self.G.load_state_dict(torch.load(self.restore_G_model_path))\n",
    "            print('Pretrained model load success!')\n",
    "\n",
    "        D_adam = optim.Adam(self.D.parameters(), lr=self.lr, betas=(0.5, 0.999))\n",
    "        G_adam = optim.Adam(self.G.parameters(), lr=self.lr, betas=(0.5, 0.999))\n",
    "\n",
    "        if self.gpu:\n",
    "            self.D = self.D.cuda()\n",
    "            self.G = self.G.cuda()\n",
    "            ones, zeros = Variable(torch.ones(self.batch_size, 1, 30, 30).cuda()), Variable(torch.zeros(self.batch_size, 1, 30, 30).cuda())\n",
    "            BCE_loss = nn.BCELoss().cuda()\n",
    "            L1_loss = nn.L1Loss().cuda()\n",
    "            MSE_loss = nn.MSELoss().cuda()\n",
    "        else:\n",
    "            ones, zeros = Variable(torch.ones(self.batch_size, 1, 30, 30)), Variable(torch.zeros(self.batch_size, 1, 30, 30))\n",
    "            BCE_loss = nn.BCELoss()\n",
    "            L1_loss = nn.L1Loss()\n",
    "            MSE_loss = nn.MSELoss()\n",
    "\n",
    "        self.D.train()\n",
    "        self.G.train()\n",
    "        print('Training Start')\n",
    "        for epoch in range(3, self.epoch_iter):\n",
    "            for step, (src, trg) in enumerate(data_loader):\n",
    "                for d_i in range(self.d_step):\n",
    "                    src, trg = iter(data_loader).next()\n",
    "                    src_data = src.cuda()\n",
    "                    trg_data = trg.cuda()\n",
    "\n",
    "                    self.D.zero_grad()\n",
    "                    self.G.zero_grad()\n",
    "\n",
    "                    src_input = Variable(src_data.cuda())\n",
    "                    trg_input = Variable(trg_data.cuda())\n",
    "\n",
    "                    src_generated = self.G(src_input)\n",
    "\n",
    "                    D_src_generated = self.D(src_generated, trg_input)\n",
    "                    D_trg_input = self.D(trg_input, trg_input)\n",
    "\n",
    "                    # training D\n",
    "                    D_fake_loss = BCE_loss(D_src_generated, zeros)\n",
    "                    D_real_loss = BCE_loss(D_trg_input, ones)\n",
    "                    D_loss = D_fake_loss + D_real_loss\n",
    "                    D_loss.backward(retain_graph=True)\n",
    "                    D_adam.step()\n",
    "                \n",
    "                for p in self.D.parameters():\n",
    "                    p.requires_grad = False\n",
    "                \n",
    "                for g_i in range(self.g_step):\n",
    "                    # training G\n",
    "                    G_fake_loss = BCE_loss(D_src_generated, ones)\n",
    "                    G_distance_loss = MSE_loss(src_generated, trg_input) * 100\n",
    "                    G_loss = G_fake_loss + G_distance_loss\n",
    "                    G_loss.backward(retain_graph=True)\n",
    "                    G_adam.step()\n",
    "                    \n",
    "                    \n",
    "                for p in self.D.parameters():\n",
    "                    p.requires_grad = True\n",
    "\n",
    "                # logging losses\n",
    "                if step % 20 == 0:\n",
    "                    print(f\"Epoch: {epoch} & Step: {step} => D-fake Loss: {D_fake_loss.data}, D-real Loss: {D_real_loss.data}, G Loss: {G_loss.data}\")\n",
    "                    \n",
    "                # save sample images \n",
    "                if step % 50 == 0:\n",
    "                    vutils.save_image(src_data[0], os.path.join(self.sample_img_path, f'epoch-{epoch}-step-{step}-src_input.jpg'))\n",
    "                    vutils.save_image(trg_data[0], os.path.join(self.sample_img_path, f'epoch-{epoch}-step-{step}-trg_input.jpg'))\n",
    "                    vutils.save_image(src_generated.data[0], os.path.join(self.sample_img_path, f'epoch-{epoch}-step-{step}-generated.jpg'))\n",
    "\n",
    "            # save model\n",
    "            torch.save(self.D.state_dict(), os.path.join(self.save_model_path, str(epoch) + 'D' + '.pth'))\n",
    "            torch.save(self.G.state_dict(), os.path.join(self.save_model_path, str(epoch) + 'G' + '.pth'))\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
