{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/9912422 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 16384/9912422 [00:00<03:24, 48441.86it/s]\u001b[A\n",
      "  0%|          | 40960/9912422 [00:00<02:42, 60651.80it/s]\u001b[A\n",
      "  1%|          | 98304/9912422 [00:01<02:02, 80434.51it/s]\u001b[A\n",
      "  2%|▏         | 155648/9912422 [00:01<01:33, 104363.59it/s]\u001b[A\n",
      "  2%|▏         | 212992/9912422 [00:01<01:13, 131883.05it/s]\u001b[A\n",
      "  3%|▎         | 270336/9912422 [00:01<00:59, 161850.53it/s]\u001b[A\n",
      "  3%|▎         | 335872/9912422 [00:01<00:48, 196306.14it/s]\u001b[A\n",
      "  4%|▍         | 401408/9912422 [00:01<00:41, 229834.36it/s]\u001b[A\n",
      "  5%|▍         | 466944/9912422 [00:02<00:35, 264186.68it/s]\u001b[A\n",
      "  5%|▌         | 540672/9912422 [00:02<00:31, 299134.90it/s]\u001b[A\n",
      "  6%|▌         | 614400/9912422 [00:02<00:27, 333081.07it/s]\u001b[A\n",
      "  7%|▋         | 696320/9912422 [00:02<00:25, 367756.57it/s]\u001b[A\n",
      "  8%|▊         | 778240/9912422 [00:02<00:23, 392142.91it/s]\u001b[A\n",
      "  9%|▊         | 860160/9912422 [00:02<00:22, 403854.23it/s]\u001b[A\n",
      " 10%|▉         | 958464/9912422 [00:03<00:20, 441143.96it/s]\u001b[A\n",
      " 11%|█         | 1056768/9912422 [00:03<00:18, 474345.70it/s]\u001b[A\n",
      " 12%|█▏        | 1155072/9912422 [00:03<00:17, 507246.91it/s]\u001b[A\n",
      " 13%|█▎        | 1261568/9912422 [00:03<00:16, 540222.53it/s]\u001b[A\n",
      " 14%|█▍        | 1376256/9912422 [00:03<00:14, 570722.28it/s]\u001b[A\n",
      " 15%|█▌        | 1490944/9912422 [00:03<00:13, 601673.15it/s]\u001b[A\n",
      " 16%|█▋        | 1613824/9912422 [00:04<00:12, 641600.24it/s]\u001b[A\n",
      " 18%|█▊        | 1736704/9912422 [00:04<00:12, 675762.07it/s]\u001b[A\n",
      " 18%|█▊        | 1818624/9912422 [00:04<00:20, 386697.32it/s]\u001b[A\n",
      " 19%|█▉        | 1900544/9912422 [00:04<00:17, 451134.71it/s]\u001b[A\n",
      " 20%|█▉        | 1974272/9912422 [00:04<00:16, 473483.46it/s]\u001b[A\n",
      " 21%|██        | 2039808/9912422 [00:05<00:23, 340786.83it/s]\u001b[A\n",
      " 72%|███████▏  | 7110656/9912422 [00:20<00:00, 3557425.97it/s]\n",
      " 22%|██▏       | 2211840/9912422 [00:11<03:35, 35754.04it/s] \u001b[A\n",
      " 23%|██▎       | 2277376/9912422 [00:11<02:33, 49681.48it/s]\u001b[A\n",
      " 24%|██▍       | 2392064/9912422 [00:11<01:49, 68840.30it/s]\u001b[A\n",
      " 25%|██▍       | 2473984/9912422 [00:11<01:20, 92607.91it/s]\u001b[A\n",
      " 26%|██▌       | 2555904/9912422 [00:11<01:00, 122568.35it/s]\u001b[A\n",
      " 27%|██▋       | 2646016/9912422 [00:11<00:45, 159512.83it/s]\u001b[A\n",
      " 28%|██▊       | 2736128/9912422 [00:12<00:35, 203515.59it/s]\u001b[A\n",
      " 29%|██▊       | 2842624/9912422 [00:12<00:27, 255726.12it/s]\u001b[A\n",
      " 29%|██▉       | 2899968/9912422 [00:12<00:23, 301233.98it/s]\u001b[A\n",
      " 30%|███       | 3014656/9912422 [00:12<00:19, 360596.73it/s]\u001b[A\n",
      " 32%|███▏      | 3137536/9912422 [00:12<00:16, 422987.37it/s]\u001b[A\n",
      " 33%|███▎      | 3260416/9912422 [00:12<00:13, 484851.60it/s]\u001b[A\n",
      " 34%|███▍      | 3383296/9912422 [00:13<00:12, 541118.07it/s]\u001b[A\n",
      " 35%|███▍      | 3457024/9912422 [00:13<00:11, 584318.77it/s]\u001b[A\n",
      " 36%|███▌      | 3530752/9912422 [00:13<00:13, 479103.84it/s]\u001b[A\n",
      " 36%|███▋      | 3596288/9912422 [00:13<00:15, 414928.26it/s]\u001b[A\n",
      " 37%|███▋      | 3694592/9912422 [00:13<00:13, 451664.09it/s]\u001b[A\n",
      " 39%|███▉      | 3842048/9912422 [00:13<00:11, 533591.75it/s]\u001b[A\n",
      " 40%|████      | 3989504/9912422 [00:14<00:09, 604529.05it/s]\u001b[A\n",
      " 42%|████▏     | 4136960/9912422 [00:14<00:08, 667944.30it/s]\u001b[A\n",
      " 43%|████▎     | 4284416/9912422 [00:14<00:07, 722540.24it/s]\u001b[A\n",
      " 45%|████▍     | 4431872/9912422 [00:14<00:07, 765315.78it/s]\u001b[A\n",
      " 46%|████▌     | 4521984/9912422 [00:14<00:07, 730268.22it/s]\u001b[A\n",
      " 47%|████▋     | 4612096/9912422 [00:14<00:08, 659356.13it/s]\u001b[A\n",
      " 48%|████▊     | 4767744/9912422 [00:15<00:07, 714747.66it/s]\u001b[A\n",
      " 50%|████▉     | 4915200/9912422 [00:15<00:06, 778515.74it/s]\u001b[A\n",
      " 51%|█████     | 5079040/9912422 [00:15<00:05, 807387.63it/s]\u001b[A\n",
      " 53%|█████▎    | 5234688/9912422 [00:15<00:05, 864153.06it/s]\u001b[A\n",
      " 54%|█████▍    | 5390336/9912422 [00:15<00:05, 886513.06it/s]\u001b[A\n",
      " 56%|█████▌    | 5545984/9912422 [00:15<00:04, 899947.12it/s]\u001b[A\n",
      " 58%|█████▊    | 5701632/9912422 [00:16<00:04, 908194.27it/s]\u001b[A\n",
      " 59%|█████▉    | 5857280/9912422 [00:16<00:04, 913001.25it/s]\u001b[A\n",
      " 61%|██████    | 6004736/9912422 [00:16<00:04, 902241.64it/s]\u001b[A\n",
      " 62%|██████▏   | 6152192/9912422 [00:16<00:04, 887594.09it/s]\u001b[A\n",
      " 64%|██████▎   | 6299648/9912422 [00:16<00:04, 880302.30it/s]\u001b[A\n",
      " 65%|██████▌   | 6455296/9912422 [00:16<00:03, 890107.93it/s]\u001b[A\n",
      " 67%|██████▋   | 6602752/9912422 [00:17<00:03, 885084.19it/s]\u001b[A\n",
      " 68%|██████▊   | 6758400/9912422 [00:17<00:03, 895162.66it/s]\u001b[A\n",
      " 70%|██████▉   | 6889472/9912422 [00:17<00:03, 988905.19it/s]\u001b[A\n",
      " 71%|███████   | 6995968/9912422 [00:17<00:03, 869294.95it/s]\u001b[A\n",
      " 72%|███████▏  | 7094272/9912422 [00:17<00:03, 773369.14it/s]\u001b[A\n",
      " 73%|███████▎  | 7249920/9912422 [00:17<00:03, 811922.77it/s]\u001b[A\n",
      " 75%|███████▍  | 7397376/9912422 [00:17<00:03, 828818.96it/s]\u001b[A\n",
      " 76%|███████▌  | 7553024/9912422 [00:18<00:02, 854763.03it/s]\u001b[A\n",
      " 78%|███████▊  | 7700480/9912422 [00:18<00:02, 860729.36it/s]\u001b[A\n",
      " 79%|███████▉  | 7864320/9912422 [00:18<00:02, 890593.15it/s]\u001b[A\n",
      " 81%|████████  | 8019968/9912422 [00:18<00:02, 905453.12it/s]\u001b[A\n",
      " 82%|████████▏ | 8175616/9912422 [00:18<00:01, 911497.68it/s]\u001b[A\n",
      " 84%|████████▍ | 8339456/9912422 [00:18<00:01, 929642.20it/s]\u001b[A\n",
      " 86%|████████▌ | 8495104/9912422 [00:19<00:01, 928696.89it/s]\u001b[A\n",
      " 87%|████████▋ | 8658944/9912422 [00:19<00:01, 940813.10it/s]\u001b[A\n",
      " 89%|████████▉ | 8814592/9912422 [00:19<00:01, 934278.10it/s]\u001b[A\n",
      " 91%|█████████ | 8986624/9912422 [00:19<00:00, 957680.70it/s]\u001b[A\n",
      " 92%|█████████▏| 9150464/9912422 [00:19<00:00, 963030.58it/s]\u001b[A\n",
      " 94%|█████████▍| 9322496/9912422 [00:19<00:00, 980783.55it/s]\u001b[A\n",
      " 96%|█████████▌| 9494528/9912422 [00:20<00:00, 993239.98it/s]\u001b[A\n",
      " 98%|█████████▊| 9674752/9912422 [00:20<00:00, 1015274.27it/s]\u001b[A\n",
      " 99%|█████████▉| 9838592/9912422 [00:20<00:00, 1145563.27it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/28881 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 16384/28881 [00:00<00:00, 92341.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "32768it [00:00, 54758.78it/s]                           \u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 16384/1648877 [00:00<00:23, 70554.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 40960/1648877 [00:00<00:19, 83482.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 98304/1648877 [00:00<00:14, 107853.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 147456/1648877 [00:01<00:11, 133076.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 204800/1648877 [00:01<00:08, 162995.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 262144/1648877 [00:01<00:07, 193339.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 319488/1648877 [00:01<00:05, 236992.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 385024/1648877 [00:01<00:04, 268890.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 450560/1648877 [00:01<00:04, 296945.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 524288/1648877 [00:02<00:03, 329077.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 598016/1648877 [00:02<00:02, 356419.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 679936/1648877 [00:02<00:02, 386208.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 761856/1648877 [00:02<00:02, 413079.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 843776/1648877 [00:02<00:01, 432862.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 925696/1648877 [00:02<00:01, 447536.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 1024000/1648877 [00:03<00:01, 480070.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 1122304/1648877 [00:03<00:01, 508249.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 1187840/1648877 [00:03<00:00, 544619.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 1245184/1648877 [00:03<00:00, 492458.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████▏ | 1343488/1648877 [00:03<00:00, 523275.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 1449984/1648877 [00:03<00:00, 548677.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 1572864/1648877 [00:04<00:00, 591000.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "1654784it [00:04, 405466.56it/s]                             \u001b[A\u001b[A\n",
      "\n",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "8192it [00:00, 23366.18it/s]            \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# MNIST dataset (images and labels)\n",
    "train_dataset = torchvision.datasets.MNIST(root='data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "9920512it [00:36, 1145563.27it/s]                             \u001b[A"
     ]
    }
   ],
   "source": [
    "# Data loader (input pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "model = nn.Linear(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "# nn.CrossEntropyLoss() computes softmax internally\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 1.9106\n",
      "Epoch [1/5], Step [200/600], Loss: 1.7783\n",
      "Epoch [1/5], Step [300/600], Loss: 1.7047\n",
      "Epoch [1/5], Step [400/600], Loss: 1.7139\n",
      "Epoch [1/5], Step [500/600], Loss: 1.6476\n",
      "Epoch [1/5], Step [600/600], Loss: 1.5479\n",
      "Epoch [2/5], Step [100/600], Loss: 1.5392\n",
      "Epoch [2/5], Step [200/600], Loss: 1.5295\n",
      "Epoch [2/5], Step [300/600], Loss: 1.3881\n",
      "Epoch [2/5], Step [400/600], Loss: 1.3842\n",
      "Epoch [2/5], Step [500/600], Loss: 1.3160\n",
      "Epoch [2/5], Step [600/600], Loss: 1.3127\n",
      "Epoch [3/5], Step [100/600], Loss: 1.2829\n",
      "Epoch [3/5], Step [200/600], Loss: 1.1843\n",
      "Epoch [3/5], Step [300/600], Loss: 1.2486\n",
      "Epoch [3/5], Step [400/600], Loss: 1.2291\n",
      "Epoch [3/5], Step [500/600], Loss: 1.1431\n",
      "Epoch [3/5], Step [600/600], Loss: 1.1940\n",
      "Epoch [4/5], Step [100/600], Loss: 1.1538\n",
      "Epoch [4/5], Step [200/600], Loss: 1.2034\n",
      "Epoch [4/5], Step [300/600], Loss: 1.0763\n",
      "Epoch [4/5], Step [400/600], Loss: 1.0716\n",
      "Epoch [4/5], Step [500/600], Loss: 1.0811\n",
      "Epoch [4/5], Step [600/600], Loss: 0.9534\n",
      "Epoch [5/5], Step [100/600], Loss: 1.0748\n",
      "Epoch [5/5], Step [200/600], Loss: 0.9857\n",
      "Epoch [5/5], Step [300/600], Loss: 0.9352\n",
      "Epoch [5/5], Step [400/600], Loss: 1.0598\n",
      "Epoch [5/5], Step [500/600], Loss: 0.9119\n",
      "Epoch [5/5], Step [600/600], Loss: 0.9860\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Reshape images to (batch_size, input_size)\n",
    "        images = images.reshape(-1, 28*28)       \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100]) torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape,outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the 10000 test images: 83 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        tops, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "\n",
    "    print('Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100]) torch.Size([100]) torch.Size([100, 10])\n",
      "tensor(8328) 8328 10000\n"
     ]
    }
   ],
   "source": [
    "print(predicted.shape,tops.shape,outputs.shape)\n",
    "print(correct,format(correct),total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
