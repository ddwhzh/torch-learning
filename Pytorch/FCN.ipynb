{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'root'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-77c87f2cdb86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-77c87f2cdb86>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0min_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minchannel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mvgg16\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'init_weights'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'D'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_zoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_urls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vgg16'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'root'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "class FCN8s(nn.Module):\n",
    "    def __init__(self, num_classes, pretrained=True):\n",
    "        super(FCN8s, self).__init__()\n",
    "        if pretrained == True:\n",
    "            vgg = models.vgg16(pretrained=True)\n",
    "        else:\n",
    "            vgg = models.vgg16(pretrained=False)\n",
    "\n",
    "        features, classifier = list(vgg.features.children()), list(vgg.classifier.children())\n",
    "\n",
    "        '''\n",
    "        100 padding for 2 reasons:\n",
    "            1) support very small input size\n",
    "            2) allow cropping in order to match size of different layers' feature maps\n",
    "        Note that the cropped part corresponds to a part of the 100 padding\n",
    "        Spatial information of different layers' feature maps cannot be align exactly because of cropping, which is bad\n",
    "        '''\n",
    "        features[0].padding = (100, 100)\n",
    "\n",
    "        self.features3 = nn.Sequential(*features[: 17])\n",
    "        self.features4 = nn.Sequential(*features[17: 24])\n",
    "        self.features5 = nn.Sequential(*features[24:])\n",
    "\n",
    "        self.score_pool3 = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "        self.score_pool4 = nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "\n",
    "        fc6 = nn.Conv2d(512, 4096, kernel_size=7)\n",
    "        fc7 = nn.Conv2d(4096, 4096, kernel_size=1)\n",
    "        score_fr = nn.Conv2d(4096, num_classes, kernel_size=1)\n",
    "\n",
    "        self.score_fr = nn.Sequential(\n",
    "            fc6, nn.ReLU(inplace=True), nn.Dropout(), fc7, nn.ReLU(inplace=True), nn.Dropout(), score_fr\n",
    "        )\n",
    "\n",
    "        self.upscore2 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, bias=False)\n",
    "        self.upscore_pool4 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=4, stride=2, bias=False)\n",
    "        self.upscore8 = nn.ConvTranspose2d(num_classes, num_classes, kernel_size=16, stride=8, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_size = x.size()\n",
    "        pool3 = self.features3(x)\n",
    "        pool4 = self.features4(pool3)\n",
    "        pool5 = self.features5(pool4)\n",
    "\n",
    "        score_fr = self.score_fr(pool5)\n",
    "        upscore2 = self.upscore2(score_fr)\n",
    "\n",
    "        score_pool4 = self.score_pool4(0.01 * pool4)\n",
    "        upscore_pool4 = self.upscore_pool4(score_pool4[:, :, 5: (5 + upscore2.size()[2]), 5: (5 + upscore2.size()[3])]\n",
    "                                           + upscore2)\n",
    "\n",
    "        score_pool3 = self.score_pool3(0.0001 * pool3)      # 将通道数标准化为类别数\n",
    "        upscore8 = self.upscore8(score_pool3[:, :, 9: (9 + upscore_pool4.size()[2]), 9: (9 + upscore_pool4.size()[3])]\n",
    "                                 + upscore_pool4)       # 反卷积\n",
    "        return upscore8[:, :, 31: (31 + x_size[2]), 31: (31 + x_size[3])].contiguous()\n",
    "\n",
    "def main():\n",
    "    model=models.vgg16(root=\"./model\",pretrained=True)\n",
    "    num_classes = 10\n",
    "    in_batch, inchannel, in_h, in_w = 4, 3, 28, 28\n",
    "    x = torch.randn(in_batch, inchannel, in_h, in_w)\n",
    "    net = FCN8s(num_classes)\n",
    "    out = net(x)\n",
    "    print(out.shape)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
